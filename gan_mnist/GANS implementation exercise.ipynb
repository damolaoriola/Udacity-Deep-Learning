{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-8f71a829c246>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Damola\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Damola\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Damola\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Damola\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#Load Datasets\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#Function to create generator and discrimninator inputs\n",
    "\n",
    "def input_mnist(input_size, z_size):\n",
    "    \n",
    "    input_real = tf.placeholder(tf.float32,[None, input_size])\n",
    "    \n",
    "    input_gen = tf.placeholder(tf.float32, [None, z_size])\n",
    "    \n",
    "    \n",
    "    return input_real, input_gen\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create generator forward pass\n",
    "\n",
    "def generator_forward(gen, input_size, n_units, reuse, alpha = 0.01):\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope('generator', reuse = reuse):\n",
    "        \n",
    "        hidden = tf.contrib.layers.fully_connected(gen, n_units, activation_fn = None)\n",
    "        \n",
    "        hidden = tf.maximum(alpha * hidden, hidden)\n",
    "        \n",
    "        logits = tf.contrib.layers.fully_connected(hidden, input_size, activation_fn = None)\n",
    "        \n",
    "        out = tf.nn.tanh(logits)\n",
    "        \n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create discriminator forward pass\n",
    "\n",
    "def discriminator_forward(x, n_units, reuse, alpha = 0.01):\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope('discriminator', reuse = reuse):\n",
    "        \n",
    "        hidden = tf.contrib.layers.fully_connected(x, n_units, activation_fn = None)\n",
    "        \n",
    "        hidden = tf.maximum(alpha * hidden, hidden)\n",
    "        \n",
    "        logits = tf.contrib.layers.fully_connected(hidden, 1, activation_fn = None)\n",
    "        \n",
    "        out = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        return logits, out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining model paramaters for tensorflow graph\n",
    "input_size = 784\n",
    "z_size = 100\n",
    "g_hidden_size = 256\n",
    "d_hidden_size = 256\n",
    "smoothing = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Damola\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Building graph parameters\n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    input_real, input_gen = input_mnist(input_size, z_size)\n",
    "    \n",
    "    Gout = generator_forward(input_gen, input_size, g_hidden_size, reuse = False, alpha = 0.01)\n",
    "    \n",
    "    D_logits_real, D_out_real = discriminator_forward(input_real, d_hidden_size, reuse = False, alpha = 0.01)\n",
    "    \n",
    "    D_logits_fake, D_out_fake = discriminator_forward(Gout, d_hidden_size, reuse = True, alpha = 0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Cost Function for the Discriminator and Generator\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = (tf.ones_like(D_logits_real) * (1 -smoothing)), \n",
    "                                                                         logits = D_logits_real))\n",
    "    \n",
    "    \n",
    "    D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = tf.zeros_like(D_logits_fake), \n",
    "                                                                         logits = D_logits_fake))\n",
    "    \n",
    "    \n",
    "    D_loss_total = D_loss_real + D_loss_fake\n",
    "        \n",
    "        \n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = tf.ones_like(D_logits_fake), \n",
    "                                                                         logits = D_logits_fake))\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building our optimizers in two stages\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    tvars = tf.trainable_variables()\n",
    "    \n",
    "    Gvars = [var for var in tvars if var.name.startswith('generator')]\n",
    "    \n",
    "    Dvars = [var for var in tvars if var.name.startswith('discriminator')]\n",
    "    \n",
    "    Gopt = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(G_loss, var_list = Gvars)\n",
    "    \n",
    "    Dopt = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(D_loss_total, var_list = Dvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 1/10000 Generator loss: 3.776102..... Discriminator loss: 0.483627..\n",
      "Epoch is 2/10000 Generator loss: 3.073650..... Discriminator loss: 0.744369..\n",
      "Epoch is 3/10000 Generator loss: 2.948622..... Discriminator loss: 0.627054..\n",
      "Epoch is 4/10000 Generator loss: 1.768833..... Discriminator loss: 1.265869..\n",
      "Epoch is 5/10000 Generator loss: 3.336259..... Discriminator loss: 1.299451..\n",
      "Epoch is 6/10000 Generator loss: 1.496265..... Discriminator loss: 1.270588..\n",
      "Epoch is 7/10000 Generator loss: 1.705066..... Discriminator loss: 1.043217..\n",
      "Epoch is 8/10000 Generator loss: 1.512172..... Discriminator loss: 1.018152..\n",
      "Epoch is 9/10000 Generator loss: 2.473562..... Discriminator loss: 0.793429..\n",
      "Epoch is 10/10000 Generator loss: 2.550111..... Discriminator loss: 0.938072..\n",
      "Epoch is 11/10000 Generator loss: 2.279166..... Discriminator loss: 0.926540..\n",
      "Epoch is 12/10000 Generator loss: 1.284037..... Discriminator loss: 1.090516..\n",
      "Epoch is 13/10000 Generator loss: 1.877444..... Discriminator loss: 1.031799..\n",
      "Epoch is 14/10000 Generator loss: 2.073791..... Discriminator loss: 1.017282..\n",
      "Epoch is 15/10000 Generator loss: 1.954462..... Discriminator loss: 1.060294..\n",
      "Epoch is 16/10000 Generator loss: 1.760621..... Discriminator loss: 0.879865..\n",
      "Epoch is 17/10000 Generator loss: 1.174226..... Discriminator loss: 1.210115..\n",
      "Epoch is 18/10000 Generator loss: 1.352042..... Discriminator loss: 1.134857..\n",
      "Epoch is 19/10000 Generator loss: 1.934507..... Discriminator loss: 1.050621..\n",
      "Epoch is 20/10000 Generator loss: 1.515202..... Discriminator loss: 1.092205..\n",
      "Epoch is 21/10000 Generator loss: 1.761741..... Discriminator loss: 1.128621..\n",
      "Epoch is 22/10000 Generator loss: 1.724739..... Discriminator loss: 0.939587..\n",
      "Epoch is 23/10000 Generator loss: 1.889026..... Discriminator loss: 1.017939..\n",
      "Epoch is 24/10000 Generator loss: 1.657956..... Discriminator loss: 1.030698..\n",
      "Epoch is 25/10000 Generator loss: 1.504231..... Discriminator loss: 1.019876..\n",
      "Epoch is 26/10000 Generator loss: 1.916306..... Discriminator loss: 0.925833..\n",
      "Epoch is 27/10000 Generator loss: 2.081087..... Discriminator loss: 0.834457..\n",
      "Epoch is 28/10000 Generator loss: 1.567236..... Discriminator loss: 1.041368..\n",
      "Epoch is 29/10000 Generator loss: 1.325659..... Discriminator loss: 0.994180..\n",
      "Epoch is 30/10000 Generator loss: 1.789762..... Discriminator loss: 1.154071..\n",
      "Epoch is 31/10000 Generator loss: 1.613390..... Discriminator loss: 0.932300..\n",
      "Epoch is 32/10000 Generator loss: 1.518590..... Discriminator loss: 1.022380..\n",
      "Epoch is 33/10000 Generator loss: 1.979775..... Discriminator loss: 0.754783..\n",
      "Epoch is 34/10000 Generator loss: 1.591144..... Discriminator loss: 1.030865..\n",
      "Epoch is 35/10000 Generator loss: 1.658413..... Discriminator loss: 0.985525..\n",
      "Epoch is 36/10000 Generator loss: 1.548795..... Discriminator loss: 0.918591..\n",
      "Epoch is 37/10000 Generator loss: 1.978702..... Discriminator loss: 0.836190..\n",
      "Epoch is 38/10000 Generator loss: 1.289942..... Discriminator loss: 1.097556..\n",
      "Epoch is 39/10000 Generator loss: 1.682805..... Discriminator loss: 0.877432..\n",
      "Epoch is 40/10000 Generator loss: 1.430757..... Discriminator loss: 0.988422..\n",
      "Epoch is 41/10000 Generator loss: 1.572985..... Discriminator loss: 0.916692..\n",
      "Epoch is 42/10000 Generator loss: 2.437948..... Discriminator loss: 0.882030..\n",
      "Epoch is 43/10000 Generator loss: 1.910453..... Discriminator loss: 0.993672..\n",
      "Epoch is 44/10000 Generator loss: 1.557158..... Discriminator loss: 1.171636..\n",
      "Epoch is 45/10000 Generator loss: 1.251480..... Discriminator loss: 1.115182..\n",
      "Epoch is 46/10000 Generator loss: 1.305037..... Discriminator loss: 1.160931..\n",
      "Epoch is 47/10000 Generator loss: 1.471171..... Discriminator loss: 0.987406..\n",
      "Epoch is 48/10000 Generator loss: 2.094328..... Discriminator loss: 0.897379..\n",
      "Epoch is 49/10000 Generator loss: 1.622101..... Discriminator loss: 0.910761..\n",
      "Epoch is 50/10000 Generator loss: 1.653026..... Discriminator loss: 1.009941..\n",
      "Epoch is 51/10000 Generator loss: 1.737164..... Discriminator loss: 1.004523..\n",
      "Epoch is 52/10000 Generator loss: 1.412479..... Discriminator loss: 0.911124..\n",
      "Epoch is 53/10000 Generator loss: 1.497176..... Discriminator loss: 0.885753..\n",
      "Epoch is 54/10000 Generator loss: 1.670796..... Discriminator loss: 0.923495..\n",
      "Epoch is 55/10000 Generator loss: 1.644906..... Discriminator loss: 1.010488..\n",
      "Epoch is 56/10000 Generator loss: 1.890336..... Discriminator loss: 0.865814..\n",
      "Epoch is 57/10000 Generator loss: 1.488490..... Discriminator loss: 0.838322..\n",
      "Epoch is 58/10000 Generator loss: 2.072094..... Discriminator loss: 0.828963..\n",
      "Epoch is 59/10000 Generator loss: 2.258835..... Discriminator loss: 0.900059..\n",
      "Epoch is 60/10000 Generator loss: 1.963460..... Discriminator loss: 0.840429..\n",
      "Epoch is 61/10000 Generator loss: 1.693041..... Discriminator loss: 0.944312..\n",
      "Epoch is 62/10000 Generator loss: 1.917097..... Discriminator loss: 0.962139..\n",
      "Epoch is 63/10000 Generator loss: 1.918814..... Discriminator loss: 1.066447..\n",
      "Epoch is 64/10000 Generator loss: 1.595504..... Discriminator loss: 0.984506..\n",
      "Epoch is 65/10000 Generator loss: 2.057712..... Discriminator loss: 0.833036..\n",
      "Epoch is 66/10000 Generator loss: 2.049982..... Discriminator loss: 0.737761..\n",
      "Epoch is 67/10000 Generator loss: 1.569587..... Discriminator loss: 1.019325..\n",
      "Epoch is 68/10000 Generator loss: 2.549506..... Discriminator loss: 0.722992..\n",
      "Epoch is 69/10000 Generator loss: 2.149763..... Discriminator loss: 1.031967..\n",
      "Epoch is 70/10000 Generator loss: 1.855411..... Discriminator loss: 0.835599..\n",
      "Epoch is 71/10000 Generator loss: 1.794893..... Discriminator loss: 0.991639..\n",
      "Epoch is 72/10000 Generator loss: 1.380009..... Discriminator loss: 1.023317..\n",
      "Epoch is 73/10000 Generator loss: 2.284667..... Discriminator loss: 0.842661..\n",
      "Epoch is 74/10000 Generator loss: 1.882157..... Discriminator loss: 0.863751..\n",
      "Epoch is 75/10000 Generator loss: 1.701544..... Discriminator loss: 0.880080..\n",
      "Epoch is 76/10000 Generator loss: 2.166960..... Discriminator loss: 0.850288..\n",
      "Epoch is 77/10000 Generator loss: 1.844985..... Discriminator loss: 0.951347..\n",
      "Epoch is 78/10000 Generator loss: 1.888616..... Discriminator loss: 0.850580..\n",
      "Epoch is 79/10000 Generator loss: 1.842532..... Discriminator loss: 0.918512..\n",
      "Epoch is 80/10000 Generator loss: 2.251760..... Discriminator loss: 0.848065..\n",
      "Epoch is 81/10000 Generator loss: 1.832647..... Discriminator loss: 0.914608..\n",
      "Epoch is 82/10000 Generator loss: 2.132948..... Discriminator loss: 0.846149..\n",
      "Epoch is 83/10000 Generator loss: 1.982304..... Discriminator loss: 0.775184..\n",
      "Epoch is 84/10000 Generator loss: 1.991113..... Discriminator loss: 1.110738..\n",
      "Epoch is 85/10000 Generator loss: 2.273774..... Discriminator loss: 0.850625..\n",
      "Epoch is 86/10000 Generator loss: 1.652754..... Discriminator loss: 0.859713..\n",
      "Epoch is 87/10000 Generator loss: 1.438782..... Discriminator loss: 0.938272..\n",
      "Epoch is 88/10000 Generator loss: 2.806817..... Discriminator loss: 0.658536..\n",
      "Epoch is 89/10000 Generator loss: 2.032806..... Discriminator loss: 0.756868..\n",
      "Epoch is 90/10000 Generator loss: 1.832454..... Discriminator loss: 0.852091..\n",
      "Epoch is 91/10000 Generator loss: 2.168828..... Discriminator loss: 0.619987..\n",
      "Epoch is 92/10000 Generator loss: 2.673818..... Discriminator loss: 0.853160..\n",
      "Epoch is 93/10000 Generator loss: 2.284908..... Discriminator loss: 0.849114..\n",
      "Epoch is 94/10000 Generator loss: 1.542444..... Discriminator loss: 0.860070..\n",
      "Epoch is 95/10000 Generator loss: 2.045604..... Discriminator loss: 0.925456..\n",
      "Epoch is 96/10000 Generator loss: 2.194471..... Discriminator loss: 0.728299..\n",
      "Epoch is 97/10000 Generator loss: 1.841653..... Discriminator loss: 0.870742..\n",
      "Epoch is 98/10000 Generator loss: 2.497258..... Discriminator loss: 0.824671..\n",
      "Epoch is 99/10000 Generator loss: 2.342252..... Discriminator loss: 0.883681..\n",
      "Epoch is 100/10000 Generator loss: 2.231561..... Discriminator loss: 0.968180..\n",
      "Epoch is 101/10000 Generator loss: 1.907739..... Discriminator loss: 1.007128..\n",
      "Epoch is 102/10000 Generator loss: 2.121990..... Discriminator loss: 0.954800..\n",
      "Epoch is 103/10000 Generator loss: 2.531785..... Discriminator loss: 0.919698..\n",
      "Epoch is 104/10000 Generator loss: 2.781484..... Discriminator loss: 0.745528..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 105/10000 Generator loss: 1.922744..... Discriminator loss: 0.699420..\n",
      "Epoch is 106/10000 Generator loss: 2.089661..... Discriminator loss: 0.824103..\n",
      "Epoch is 107/10000 Generator loss: 2.287487..... Discriminator loss: 0.851067..\n",
      "Epoch is 108/10000 Generator loss: 1.844957..... Discriminator loss: 0.999037..\n",
      "Epoch is 109/10000 Generator loss: 1.827008..... Discriminator loss: 0.939719..\n",
      "Epoch is 110/10000 Generator loss: 2.190348..... Discriminator loss: 0.896544..\n",
      "Epoch is 111/10000 Generator loss: 1.809031..... Discriminator loss: 0.848494..\n",
      "Epoch is 112/10000 Generator loss: 2.441585..... Discriminator loss: 0.795760..\n",
      "Epoch is 113/10000 Generator loss: 2.740982..... Discriminator loss: 0.923046..\n",
      "Epoch is 114/10000 Generator loss: 1.887067..... Discriminator loss: 0.965169..\n",
      "Epoch is 115/10000 Generator loss: 2.064773..... Discriminator loss: 0.779370..\n",
      "Epoch is 116/10000 Generator loss: 2.165342..... Discriminator loss: 0.900599..\n",
      "Epoch is 117/10000 Generator loss: 2.486011..... Discriminator loss: 0.734325..\n",
      "Epoch is 118/10000 Generator loss: 1.551969..... Discriminator loss: 0.952537..\n",
      "Epoch is 119/10000 Generator loss: 1.881842..... Discriminator loss: 0.878943..\n",
      "Epoch is 120/10000 Generator loss: 2.118152..... Discriminator loss: 0.741140..\n",
      "Epoch is 121/10000 Generator loss: 2.827326..... Discriminator loss: 0.793497..\n",
      "Epoch is 122/10000 Generator loss: 1.441406..... Discriminator loss: 0.997365..\n",
      "Epoch is 123/10000 Generator loss: 2.215214..... Discriminator loss: 0.753760..\n",
      "Epoch is 124/10000 Generator loss: 1.713555..... Discriminator loss: 0.898452..\n",
      "Epoch is 125/10000 Generator loss: 1.733573..... Discriminator loss: 0.830913..\n",
      "Epoch is 126/10000 Generator loss: 2.403420..... Discriminator loss: 0.911107..\n",
      "Epoch is 127/10000 Generator loss: 2.232598..... Discriminator loss: 0.847484..\n",
      "Epoch is 128/10000 Generator loss: 2.396969..... Discriminator loss: 0.738075..\n",
      "Epoch is 129/10000 Generator loss: 1.748028..... Discriminator loss: 0.901532..\n",
      "Epoch is 130/10000 Generator loss: 2.483537..... Discriminator loss: 0.839678..\n",
      "Epoch is 131/10000 Generator loss: 1.748434..... Discriminator loss: 0.996671..\n",
      "Epoch is 132/10000 Generator loss: 1.954691..... Discriminator loss: 0.902058..\n",
      "Epoch is 133/10000 Generator loss: 1.985921..... Discriminator loss: 0.918532..\n",
      "Epoch is 134/10000 Generator loss: 1.911191..... Discriminator loss: 0.801683..\n",
      "Epoch is 135/10000 Generator loss: 2.263522..... Discriminator loss: 0.742351..\n",
      "Epoch is 136/10000 Generator loss: 1.563837..... Discriminator loss: 0.954683..\n",
      "Epoch is 137/10000 Generator loss: 2.521390..... Discriminator loss: 0.715746..\n",
      "Epoch is 138/10000 Generator loss: 1.841277..... Discriminator loss: 1.041259..\n",
      "Epoch is 139/10000 Generator loss: 2.349519..... Discriminator loss: 0.726581..\n",
      "Epoch is 140/10000 Generator loss: 1.908843..... Discriminator loss: 0.854758..\n",
      "Epoch is 141/10000 Generator loss: 1.843308..... Discriminator loss: 0.776364..\n",
      "Epoch is 142/10000 Generator loss: 1.921828..... Discriminator loss: 0.724103..\n",
      "Epoch is 143/10000 Generator loss: 1.339914..... Discriminator loss: 0.887575..\n",
      "Epoch is 144/10000 Generator loss: 1.780493..... Discriminator loss: 0.873022..\n",
      "Epoch is 145/10000 Generator loss: 1.779810..... Discriminator loss: 0.784499..\n",
      "Epoch is 146/10000 Generator loss: 2.190557..... Discriminator loss: 0.944019..\n",
      "Epoch is 147/10000 Generator loss: 1.747351..... Discriminator loss: 0.881127..\n",
      "Epoch is 148/10000 Generator loss: 2.368188..... Discriminator loss: 0.760380..\n",
      "Epoch is 149/10000 Generator loss: 1.778085..... Discriminator loss: 0.962145..\n",
      "Epoch is 150/10000 Generator loss: 1.921090..... Discriminator loss: 0.660810..\n",
      "Epoch is 151/10000 Generator loss: 2.113154..... Discriminator loss: 0.700954..\n",
      "Epoch is 152/10000 Generator loss: 2.093450..... Discriminator loss: 1.077434..\n",
      "Epoch is 153/10000 Generator loss: 1.978830..... Discriminator loss: 0.876635..\n",
      "Epoch is 154/10000 Generator loss: 2.456638..... Discriminator loss: 0.766282..\n",
      "Epoch is 155/10000 Generator loss: 2.280915..... Discriminator loss: 0.809153..\n",
      "Epoch is 156/10000 Generator loss: 1.917312..... Discriminator loss: 0.876626..\n",
      "Epoch is 157/10000 Generator loss: 2.297673..... Discriminator loss: 0.669344..\n",
      "Epoch is 158/10000 Generator loss: 1.999199..... Discriminator loss: 0.958340..\n",
      "Epoch is 159/10000 Generator loss: 2.257423..... Discriminator loss: 0.811074..\n",
      "Epoch is 160/10000 Generator loss: 1.661355..... Discriminator loss: 0.915612..\n",
      "Epoch is 161/10000 Generator loss: 2.041966..... Discriminator loss: 0.975195..\n",
      "Epoch is 162/10000 Generator loss: 2.686504..... Discriminator loss: 0.754736..\n",
      "Epoch is 163/10000 Generator loss: 1.994559..... Discriminator loss: 1.075225..\n",
      "Epoch is 164/10000 Generator loss: 2.331527..... Discriminator loss: 0.758655..\n",
      "Epoch is 165/10000 Generator loss: 2.993861..... Discriminator loss: 0.804909..\n",
      "Epoch is 166/10000 Generator loss: 2.006835..... Discriminator loss: 0.757694..\n",
      "Epoch is 167/10000 Generator loss: 2.116651..... Discriminator loss: 0.838221..\n",
      "Epoch is 168/10000 Generator loss: 2.776206..... Discriminator loss: 0.719192..\n",
      "Epoch is 169/10000 Generator loss: 1.939320..... Discriminator loss: 0.822188..\n",
      "Epoch is 170/10000 Generator loss: 2.160827..... Discriminator loss: 0.803874..\n",
      "Epoch is 171/10000 Generator loss: 2.052049..... Discriminator loss: 0.811504..\n",
      "Epoch is 172/10000 Generator loss: 2.062390..... Discriminator loss: 0.748151..\n",
      "Epoch is 173/10000 Generator loss: 1.145486..... Discriminator loss: 1.263734..\n",
      "Epoch is 174/10000 Generator loss: 1.586559..... Discriminator loss: 0.981607..\n",
      "Epoch is 175/10000 Generator loss: 1.865983..... Discriminator loss: 0.925791..\n",
      "Epoch is 176/10000 Generator loss: 1.750819..... Discriminator loss: 0.905904..\n",
      "Epoch is 177/10000 Generator loss: 2.068916..... Discriminator loss: 0.758203..\n",
      "Epoch is 178/10000 Generator loss: 2.162350..... Discriminator loss: 0.731897..\n",
      "Epoch is 179/10000 Generator loss: 2.226501..... Discriminator loss: 0.745781..\n",
      "Epoch is 180/10000 Generator loss: 1.662565..... Discriminator loss: 0.845713..\n",
      "Epoch is 181/10000 Generator loss: 2.426327..... Discriminator loss: 0.776952..\n",
      "Epoch is 182/10000 Generator loss: 2.423277..... Discriminator loss: 0.733398..\n",
      "Epoch is 183/10000 Generator loss: 2.092444..... Discriminator loss: 0.712257..\n",
      "Epoch is 184/10000 Generator loss: 2.832012..... Discriminator loss: 0.854376..\n",
      "Epoch is 185/10000 Generator loss: 2.478994..... Discriminator loss: 0.651365..\n",
      "Epoch is 186/10000 Generator loss: 2.340695..... Discriminator loss: 0.869404..\n",
      "Epoch is 187/10000 Generator loss: 2.458744..... Discriminator loss: 0.813031..\n",
      "Epoch is 188/10000 Generator loss: 1.651423..... Discriminator loss: 0.892518..\n",
      "Epoch is 189/10000 Generator loss: 2.402230..... Discriminator loss: 0.845983..\n",
      "Epoch is 190/10000 Generator loss: 2.208511..... Discriminator loss: 0.810696..\n",
      "Epoch is 191/10000 Generator loss: 1.787064..... Discriminator loss: 0.807098..\n",
      "Epoch is 192/10000 Generator loss: 1.984651..... Discriminator loss: 0.825243..\n",
      "Epoch is 193/10000 Generator loss: 2.181246..... Discriminator loss: 0.819820..\n",
      "Epoch is 194/10000 Generator loss: 2.392156..... Discriminator loss: 0.761855..\n",
      "Epoch is 195/10000 Generator loss: 1.953010..... Discriminator loss: 0.771419..\n",
      "Epoch is 196/10000 Generator loss: 2.811669..... Discriminator loss: 0.678858..\n",
      "Epoch is 197/10000 Generator loss: 2.203027..... Discriminator loss: 0.810043..\n",
      "Epoch is 198/10000 Generator loss: 1.986990..... Discriminator loss: 0.829862..\n",
      "Epoch is 199/10000 Generator loss: 1.958613..... Discriminator loss: 0.805444..\n",
      "Epoch is 200/10000 Generator loss: 2.200773..... Discriminator loss: 0.677761..\n",
      "Epoch is 201/10000 Generator loss: 2.800287..... Discriminator loss: 0.662786..\n",
      "Epoch is 202/10000 Generator loss: 2.197426..... Discriminator loss: 0.870867..\n",
      "Epoch is 203/10000 Generator loss: 2.949897..... Discriminator loss: 0.748376..\n",
      "Epoch is 204/10000 Generator loss: 1.858968..... Discriminator loss: 0.756000..\n",
      "Epoch is 205/10000 Generator loss: 1.747236..... Discriminator loss: 0.729682..\n",
      "Epoch is 206/10000 Generator loss: 2.241015..... Discriminator loss: 0.813653..\n",
      "Epoch is 207/10000 Generator loss: 2.396215..... Discriminator loss: 0.861328..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 208/10000 Generator loss: 2.041863..... Discriminator loss: 0.701495..\n",
      "Epoch is 209/10000 Generator loss: 2.251768..... Discriminator loss: 0.758186..\n",
      "Epoch is 210/10000 Generator loss: 2.126102..... Discriminator loss: 0.732893..\n",
      "Epoch is 211/10000 Generator loss: 1.687543..... Discriminator loss: 0.891403..\n",
      "Epoch is 212/10000 Generator loss: 2.072622..... Discriminator loss: 0.921988..\n",
      "Epoch is 213/10000 Generator loss: 2.233489..... Discriminator loss: 0.778828..\n",
      "Epoch is 214/10000 Generator loss: 2.501805..... Discriminator loss: 0.753394..\n",
      "Epoch is 215/10000 Generator loss: 2.453665..... Discriminator loss: 0.857348..\n",
      "Epoch is 216/10000 Generator loss: 2.020719..... Discriminator loss: 0.811489..\n",
      "Epoch is 217/10000 Generator loss: 2.004179..... Discriminator loss: 0.856757..\n",
      "Epoch is 218/10000 Generator loss: 2.293870..... Discriminator loss: 0.668270..\n",
      "Epoch is 219/10000 Generator loss: 1.939859..... Discriminator loss: 0.841539..\n",
      "Epoch is 220/10000 Generator loss: 2.785314..... Discriminator loss: 0.697006..\n",
      "Epoch is 221/10000 Generator loss: 2.299756..... Discriminator loss: 0.833453..\n",
      "Epoch is 222/10000 Generator loss: 2.366235..... Discriminator loss: 0.686380..\n",
      "Epoch is 223/10000 Generator loss: 2.627841..... Discriminator loss: 0.685090..\n",
      "Epoch is 224/10000 Generator loss: 3.020134..... Discriminator loss: 0.793197..\n",
      "Epoch is 225/10000 Generator loss: 1.911191..... Discriminator loss: 0.981322..\n",
      "Epoch is 226/10000 Generator loss: 2.345321..... Discriminator loss: 0.873984..\n",
      "Epoch is 227/10000 Generator loss: 1.941768..... Discriminator loss: 0.687633..\n",
      "Epoch is 228/10000 Generator loss: 2.978104..... Discriminator loss: 0.907142..\n",
      "Epoch is 229/10000 Generator loss: 1.893154..... Discriminator loss: 0.742445..\n",
      "Epoch is 230/10000 Generator loss: 1.916113..... Discriminator loss: 0.879544..\n",
      "Epoch is 231/10000 Generator loss: 2.419893..... Discriminator loss: 0.663099..\n",
      "Epoch is 232/10000 Generator loss: 1.780991..... Discriminator loss: 0.922453..\n",
      "Epoch is 233/10000 Generator loss: 2.092970..... Discriminator loss: 0.838072..\n",
      "Epoch is 234/10000 Generator loss: 2.549514..... Discriminator loss: 0.835704..\n",
      "Epoch is 235/10000 Generator loss: 2.073747..... Discriminator loss: 0.659876..\n",
      "Epoch is 236/10000 Generator loss: 1.973094..... Discriminator loss: 0.804170..\n",
      "Epoch is 237/10000 Generator loss: 2.417116..... Discriminator loss: 0.893448..\n",
      "Epoch is 238/10000 Generator loss: 2.037200..... Discriminator loss: 0.704585..\n",
      "Epoch is 239/10000 Generator loss: 2.465799..... Discriminator loss: 0.753468..\n",
      "Epoch is 240/10000 Generator loss: 2.350218..... Discriminator loss: 0.874368..\n",
      "Epoch is 241/10000 Generator loss: 2.223307..... Discriminator loss: 0.685948..\n",
      "Epoch is 242/10000 Generator loss: 1.849650..... Discriminator loss: 0.887821..\n",
      "Epoch is 243/10000 Generator loss: 2.355925..... Discriminator loss: 0.779898..\n",
      "Epoch is 244/10000 Generator loss: 1.697232..... Discriminator loss: 0.904255..\n",
      "Epoch is 245/10000 Generator loss: 2.107028..... Discriminator loss: 0.755422..\n",
      "Epoch is 246/10000 Generator loss: 2.504453..... Discriminator loss: 0.861261..\n",
      "Epoch is 247/10000 Generator loss: 1.901540..... Discriminator loss: 0.983900..\n",
      "Epoch is 248/10000 Generator loss: 2.221488..... Discriminator loss: 0.783500..\n",
      "Epoch is 249/10000 Generator loss: 1.394398..... Discriminator loss: 1.004936..\n",
      "Epoch is 250/10000 Generator loss: 1.605433..... Discriminator loss: 0.904579..\n",
      "Epoch is 251/10000 Generator loss: 2.070683..... Discriminator loss: 0.830352..\n",
      "Epoch is 252/10000 Generator loss: 2.432461..... Discriminator loss: 0.809318..\n",
      "Epoch is 253/10000 Generator loss: 2.411136..... Discriminator loss: 0.727652..\n",
      "Epoch is 254/10000 Generator loss: 2.258271..... Discriminator loss: 0.820646..\n",
      "Epoch is 255/10000 Generator loss: 2.239365..... Discriminator loss: 0.797473..\n",
      "Epoch is 256/10000 Generator loss: 2.494302..... Discriminator loss: 0.776606..\n",
      "Epoch is 257/10000 Generator loss: 2.840187..... Discriminator loss: 0.709774..\n",
      "Epoch is 258/10000 Generator loss: 2.026438..... Discriminator loss: 0.732771..\n",
      "Epoch is 259/10000 Generator loss: 2.465725..... Discriminator loss: 0.820963..\n",
      "Epoch is 260/10000 Generator loss: 2.824116..... Discriminator loss: 0.693372..\n",
      "Epoch is 261/10000 Generator loss: 1.895239..... Discriminator loss: 0.776320..\n",
      "Epoch is 262/10000 Generator loss: 2.188438..... Discriminator loss: 0.790850..\n",
      "Epoch is 263/10000 Generator loss: 1.990970..... Discriminator loss: 0.750071..\n",
      "Epoch is 264/10000 Generator loss: 1.893777..... Discriminator loss: 0.784146..\n",
      "Epoch is 265/10000 Generator loss: 2.189992..... Discriminator loss: 0.743251..\n",
      "Epoch is 266/10000 Generator loss: 1.664629..... Discriminator loss: 1.044492..\n",
      "Epoch is 267/10000 Generator loss: 1.808815..... Discriminator loss: 0.870408..\n",
      "Epoch is 268/10000 Generator loss: 2.204284..... Discriminator loss: 0.934176..\n",
      "Epoch is 269/10000 Generator loss: 2.116925..... Discriminator loss: 0.779480..\n",
      "Epoch is 270/10000 Generator loss: 2.208440..... Discriminator loss: 0.750686..\n",
      "Epoch is 271/10000 Generator loss: 2.553643..... Discriminator loss: 0.660028..\n",
      "Epoch is 272/10000 Generator loss: 1.754929..... Discriminator loss: 0.910526..\n",
      "Epoch is 273/10000 Generator loss: 1.974786..... Discriminator loss: 0.776450..\n",
      "Epoch is 274/10000 Generator loss: 2.217325..... Discriminator loss: 0.712937..\n",
      "Epoch is 275/10000 Generator loss: 2.045693..... Discriminator loss: 0.749670..\n",
      "Epoch is 276/10000 Generator loss: 2.101470..... Discriminator loss: 0.812367..\n",
      "Epoch is 277/10000 Generator loss: 1.477218..... Discriminator loss: 0.968659..\n",
      "Epoch is 278/10000 Generator loss: 2.008086..... Discriminator loss: 0.883137..\n",
      "Epoch is 279/10000 Generator loss: 2.495478..... Discriminator loss: 0.823348..\n",
      "Epoch is 280/10000 Generator loss: 2.504864..... Discriminator loss: 0.830583..\n",
      "Epoch is 281/10000 Generator loss: 2.094044..... Discriminator loss: 0.858055..\n",
      "Epoch is 282/10000 Generator loss: 2.673641..... Discriminator loss: 0.751531..\n",
      "Epoch is 283/10000 Generator loss: 1.951938..... Discriminator loss: 0.775332..\n",
      "Epoch is 284/10000 Generator loss: 2.096863..... Discriminator loss: 0.755208..\n",
      "Epoch is 285/10000 Generator loss: 2.537322..... Discriminator loss: 0.878917..\n",
      "Epoch is 286/10000 Generator loss: 2.298446..... Discriminator loss: 0.619631..\n",
      "Epoch is 287/10000 Generator loss: 2.055972..... Discriminator loss: 0.720620..\n",
      "Epoch is 288/10000 Generator loss: 1.976090..... Discriminator loss: 0.679186..\n",
      "Epoch is 289/10000 Generator loss: 2.645289..... Discriminator loss: 0.689423..\n",
      "Epoch is 290/10000 Generator loss: 2.600062..... Discriminator loss: 0.693522..\n",
      "Epoch is 291/10000 Generator loss: 2.138633..... Discriminator loss: 0.759718..\n",
      "Epoch is 292/10000 Generator loss: 1.957682..... Discriminator loss: 0.753218..\n",
      "Epoch is 293/10000 Generator loss: 1.743659..... Discriminator loss: 0.927284..\n",
      "Epoch is 294/10000 Generator loss: 2.211427..... Discriminator loss: 0.751875..\n",
      "Epoch is 295/10000 Generator loss: 1.852644..... Discriminator loss: 0.916691..\n",
      "Epoch is 296/10000 Generator loss: 2.728198..... Discriminator loss: 0.739573..\n",
      "Epoch is 297/10000 Generator loss: 2.138931..... Discriminator loss: 0.780584..\n",
      "Epoch is 298/10000 Generator loss: 2.296025..... Discriminator loss: 0.761924..\n",
      "Epoch is 299/10000 Generator loss: 1.758312..... Discriminator loss: 0.774578..\n",
      "Epoch is 300/10000 Generator loss: 2.204468..... Discriminator loss: 0.816165..\n",
      "Epoch is 301/10000 Generator loss: 2.744185..... Discriminator loss: 0.692898..\n",
      "Epoch is 302/10000 Generator loss: 2.483046..... Discriminator loss: 0.972283..\n",
      "Epoch is 303/10000 Generator loss: 2.917894..... Discriminator loss: 0.623116..\n",
      "Epoch is 304/10000 Generator loss: 1.599856..... Discriminator loss: 0.764808..\n",
      "Epoch is 305/10000 Generator loss: 2.211989..... Discriminator loss: 0.727981..\n",
      "Epoch is 306/10000 Generator loss: 1.924142..... Discriminator loss: 0.747515..\n",
      "Epoch is 307/10000 Generator loss: 1.983555..... Discriminator loss: 0.953189..\n",
      "Epoch is 308/10000 Generator loss: 2.180707..... Discriminator loss: 0.907773..\n",
      "Epoch is 309/10000 Generator loss: 2.125037..... Discriminator loss: 0.722942..\n",
      "Epoch is 310/10000 Generator loss: 2.331543..... Discriminator loss: 0.794727..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 311/10000 Generator loss: 2.158110..... Discriminator loss: 0.863138..\n",
      "Epoch is 312/10000 Generator loss: 1.552622..... Discriminator loss: 0.939817..\n",
      "Epoch is 313/10000 Generator loss: 1.992672..... Discriminator loss: 0.788061..\n",
      "Epoch is 314/10000 Generator loss: 2.182751..... Discriminator loss: 0.830631..\n",
      "Epoch is 315/10000 Generator loss: 2.208498..... Discriminator loss: 0.761964..\n",
      "Epoch is 316/10000 Generator loss: 2.346349..... Discriminator loss: 0.883334..\n",
      "Epoch is 317/10000 Generator loss: 2.340498..... Discriminator loss: 0.943948..\n",
      "Epoch is 318/10000 Generator loss: 2.747312..... Discriminator loss: 0.796751..\n",
      "Epoch is 319/10000 Generator loss: 2.052138..... Discriminator loss: 0.750252..\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "samples = []\n",
    "\n",
    "losses = []\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph = graph) as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for ii in range(mnist.train.num_examples//batch_size):\n",
    "            \n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            batch_images = batch[0].reshape((batch_size, input_size))\n",
    "            \n",
    "            batch_images = batch_images *2 - 1\n",
    "            \n",
    "            batch_z = np.random.uniform(-1, 1, size = (batch_size, z_size))\n",
    "            \n",
    "            _ = sess.run(Dopt, feed_dict = {input_real:batch_images, input_gen: batch_z})\n",
    "            \n",
    "            _ = sess.run(Gopt, feed_dict = {input_gen: batch_z})\n",
    "            \n",
    "            \n",
    "        #end of each epoch, calculate loss\n",
    "        \n",
    "        Genloss = sess.run(G_loss, feed_dict = {input_gen: batch_z})\n",
    "        \n",
    "        Disloss = sess.run(D_loss_total, {input_real: batch_images, input_gen: batch_z})\n",
    "        \n",
    "        \n",
    "        print('Epoch is {}/{}' .format (e + 1, epochs),\n",
    "              \n",
    "              \"Generator loss: {:4f}.....\". format(Genloss),\n",
    "              \n",
    "              \"Discriminator loss: {:4f}..\".format(Disloss))\n",
    "        \n",
    "        #save losses to visalize learning curves\n",
    "        \n",
    "        losses.append((Genloss, Disloss))\n",
    "        \n",
    "        \n",
    "        #sample from generator after each epoch\n",
    "        \n",
    "        sample_z = np.random.uniform(-1, 1, size = (8, z_size))\n",
    "        \n",
    "        samples_z = sess.run(generator_forward(input_gen, input_size, g_hidden_size, reuse = True, alpha = 0.01),\n",
    "                             feed_dict = {input_gen: sample_z})\n",
    "        \n",
    "        \n",
    "        samples.append(samples_z)\n",
    "        \n",
    "        saver.save(sess, './checkpoints/generatorg.ckpt')\n",
    "        \n",
    "        \n",
    " #save samples after training\n",
    "\n",
    "    with open ('train_samples_g.pl', 'wb') as f:\n",
    "        \n",
    "        pl.dump(samples, f)\n",
    "        \n",
    "        \n",
    "        \n",
    "              \n",
    "              \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "loss = np.array(losses)\n",
    "plt.plot(loss.T[0], label = 'generator')\n",
    "plt.plot(loss.T[1], label = 'discriminator')\n",
    "plt.title('Training loss generator  & discriminator')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Samples from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_samples(epoch, samples):\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize = (9, 9), nrows = 4, ncols = 4, sharey = True, sharex = True)\n",
    "    \n",
    "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
    "    \n",
    "        im = ax.imshow(img.reshape((28,28)), cmap = 'Greys_r')\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples from generator taken while training\n",
    "with open('train_samples_3.pl', 'rb') as f:\n",
    "    samples = pl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = view_samples(999, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/generatorg.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 648x648 with 16 Axes>,\n",
       " array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000029889DA3470>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889AFE278>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889B253C8>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889B4C6A0>],\n",
       "        [<matplotlib.axes._subplots.AxesSubplot object at 0x0000029889B73978>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889B9DC50>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889BC4F28>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889BF5208>],\n",
       "        [<matplotlib.axes._subplots.AxesSubplot object at 0x0000029889C1C518>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889F157F0>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889F3FAC8>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889F68DA0>],\n",
       "        [<matplotlib.axes._subplots.AxesSubplot object at 0x0000029889F990B8>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889FC1390>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x0000029889FEA668>,\n",
       "         <matplotlib.axes._subplots.AxesSubplot object at 0x000002988A012940>]],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAIMCAYAAABYAb6jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XeY1cW9x/HvSG9SRHpVCUVDELmgxiDREJEYsSQaNbEixqiPRDSCmmi8uRGjV1PkxqASUYkVjZibxItEVKLYEKUqKNJcOqL04tw/OPvz9/3CnrLnzGn7fj2PD/PZ2T1nds/s2fE385tx3nsBAADItQMK3QAAAFCeGGQAAIAgGGQAAIAgGGQAAIAgGGQAAIAgGGQAAIAgGGQAAIAgGGQAAIAgshpkOOeGOOfed84tds6NzlWjAABA6XPV3fHTOVdLRD4QkcEiskJE3hSRc7z383PXPAAAUKpqZ/G1/UVksff+IxER59xjIjJMRKocZDjn2MO8RHjvXcjHpy+UDvpC4R1wwJcXnb/44ouCtYO+gErp9oVsBhntRWR5LK8QkQH2k5xzI0RkRBbPgzJBX0Al+kJmGjRoEJW3bNlSwJbkHn2hvGUzXfJ9ETnJez88kX8kIv2991cl+RpGqSWC/2NBJfpC4TVq1CgqF3KQQV9ApXxcyVghIh1juYOIfJLF4wEA9qPcrl6g5sjm7pI3RaSbc66rc66uiPxARKbkplkAAKDUVftKhvd+t3PuShF5XkRqicgE7/28nLUMAACUtGqvyajWkzHfVjKYe0Ul+gIq0RdQKd2+wI6fAAAgCAYZAAAgCAYZAAAgiGxuYQUAlJFatWqpvGfPngK1BOWCKxkAACAIBhkAACAIBhkAACAI1mQAAESksCe8ojxxJQMAAATBIAMAAATBIAMAAATBmowsOae3b2/QoEHSz9++fbvKzIGWNruvQFzdunVV/vWvf63y8OHDVX7xxRdV/vGPfxyVN27cqOq2bduWUTtRWPZ94oAD9P/fFct+FPk8y6qY2dfL5lTv2/H3Bfva2sfq3r27yjNmzFD5ySefVPmqq66Kyrt3707aDtvPCvH3hisZAAAgCAYZAAAgCAYZAAAgiBq5JsPOldt5qlTzXB07dozKt912m6o788wzVd61a5fKl112mcqPPvpo8saiqMXnW+16nNGjR6s8YsQIlevXr6/ykCFDVD7yyCOj8v/+7/9m1U6k1rp1a5XXrl2rsl2vYOe7x4wZE5UHDhyo6o4++miV7Ws/f/58lfv27asya7cKq1GjRirbtXV2nUXDhg2j8tatW1XdoYceqvKf//xnle3fp06dOiV9rmSKod9wJQMAAATBIAMAAATBIAMAAARRI9dk2HUSlp1rjc+viYgMGzYsKtu51LPOOktlO/f6pz/9SWXWZJS2+Ot72mmnqbqRI0eqbOdaU92Lb+eBEdbq1atVtq+H3RPlpJNOUtmuuYmzr719rDZt2iR97mzYx2IvjNTsz6xevXoqt2jRQmW7jm/Hjh1RuUmTJqrO7ovRpUsXle3v/aBBg1Ru3rx5VF6zZo0UO65kAACAIBhkAACAIBhkAACAIGrkmgw739avXz+Vjz32WJXXr1+v8ksvvRSVly1bpuric3EiInfccYfK9t57hNe2bVuV4+eA7Ny5U9Wluq/czpdeeumlUflXv/qVqrPzuKnmxu0ZB++8807StiCsZs2aqXz66aerfPPNN6v88ccfR+VbbrlF1cX31hHZd22W7Su5PNuENRjpif/Me/Tooeqefvpple3v5jXXXKPypk2borJdj7Nly5ak+eCDD1a5dm39Z3rz5s37tL2YcSUDAAAEwSADAAAEkffpkvglqXxueRq/5DR06FBVd//996u8cOFClf/whz+ovGDBgqhsL2P+61//Uvnzzz9Xec6cOWm2GOmy20F37dpV5TfeeEPlTPqgneKwW39ffPHFVX6uZS+Bp5ouKYXb08qJff3sLaq33nqryu+9957KZ599dlS2l7Q7d+6ssu0LdpvqYjn6vZSlugXZvgbxbfwfeeQRVWensy655BKVt23bVmU77O2tH3zwgcqtWrVSOdX7iP0+ih1XMgAAQBAMMgAAQBApBxnOuQnOuTXOubmxj7Vwzk11zi1K/Ns82WMAAICaJ501GQ+KyD0i8lDsY6NFZJr3fqxzbnQiX5/OExbq6Nn4/PdVV12l6uwtQnYO/7nnnlM52VHwn376qcr2VqfDDjssdWOREXsL2MyZM5N+fiZ9ML6Fr8i+tzHG19xkO49u52rt94Ww7PvAb37zG5XtrYjXXnutyvF1GHZe3b6H2PUA9j2nGI7oLnX2NbA/U3s7enxbePu+feWVV6psj2/PpB1HH320yna9h2W3RahTp07az10MUl7J8N6/LCIbzIeHicjERHmiiJwmAAAAMdW9u6S1975CRMR7X+Gca1XVJzrnRohI1ScHocagL6ASfQGV6AvlLfgtrN778SIyXkTEOcfWczUYfQGV6AuoRF8ob9UdZKx2zrVNXMVoKyJFf0N/fD7uuuuuU3XxLWBFRJYsWVLt57HzZWPHjlU5l/PsHOG8V8htdo877jiVW7ZsqXJ8PtW+9naO374+9t562y9r6utZKHZNjf1dXbRokcpLly5VOf569+7dW9X17NlT5V27dql82223ZdbYDNh9FWrKHhyp1rXYdRWjRo2KynZ/o0x/ZvE1N506dVJ1Dz/8sMqp3ideffVVle1RCMWuurewThGRCxLlC0Tk2dw0BwAAlIt0bmF9VEReE5HuzrkVzrlLRGSsiAx2zi0SkcGJDAAAEEk5XeK9P6eKqhNz3BYAAFBGasxR7/F5rnfffVfV1a9fP6PHiq+FaNy4sao7//zzVY4f/ywi8uCDD2b0XHENGjRQ2c61ltoRwKXghhtuUPmQQw5RuWHDhlE51f3u1vLly1WePXu2yvE1HjVlHr2YdOjQQWW7X4E9Drxt27ZR2a6vsfti2P10Zs2aVe12pmL7jt3vo9Tm+HPFrouxr0km7Htx9+7do/JLL72k6lLtc2H72RNPPJHR1xcbthUHAABBMMgAAABBMMgAAABB1Jg1GXF2/uyiiy5S+bPPPlN5xYoVKsfXZEyaNEnV2f3wb775ZpWTnXuSip1btfssIPcWLFigct++fVWOz7XbfUsse9/+7373O5Xtfi3Z9BVkLtXr165dO5XtXHl8jv/QQw9N+lgTJ05UOZ/rImrqGoxs2L0s7BlUBx98sMqXXnppVD7ooIOSPrbdF+PPf/6zyn//+99VLrX3fa5kAACAIBhkAACAIGrkdIm9fHX33XerbG9tsrcUbd++PSq3bt1a1dlb1VauXFntdjZt2jRpOxDePffco/L3v/99leO3sKZiL3O++eabKtvpEbYVzy87HdmxY0eVDz/88KT1l19+eVTu1q2bqrOv5UMPPVTtdiL/7O+m3WLe/s1o37592o9tp1Ftttvbx//+lAKuZAAAgCAYZAAAgCAYZAAAgCBq5JqMtWvXqmyP9bVz5zavWrUqKttbl+yajKlTp1a7nfaWRuTfnDlzVLZ9xW71HmdvibTzunZ7e9Zg7HX22Wer/PjjjxekHXab6ddee03l+fPnqxyfS+/Tp4+qs7e2r1u3LhdNRIGk2k5g9erVaT+WfV/4+c9/rrJ9zyk1XMkAAABBMMgAAABBMMgAAABB1Mg1GfY+5K5duyb9/DZt2qjcv3//qHzcccepuoULF6qc6vhgu8V5fI6fo9sLz24nbNfcxNk1GHaNhT3O2/ZD7FWoNRip2NfLHj/w/vvvR2Xbb+xeB+vXr89x61BIdt3EV7/61aic6n3B7pmSzZHzxYgrGQAAIAgGGQAAIAgGGQAAIIgauSbDSnUfsp2L/eY3v1nl55555pkZPbd9bNZhFJcjjjhC5QMPPFDlZGs07Gs7ZcoUldkXo7TZ137EiBFR2a61GjdunMqsxykvdt1er169qvxcu5bnmmuuUbnc3he4kgEAAIJgkAEAAIJgkAEAAIJgTUYa7D713bt3j8p23/lM11SU2/xbqbPz7D179lTZzrUns3PnTpWffPLJ6jcMRcfufzBw4MCobN8X7r//fpX5vS9tdh+UW2+9VeVka7WGDh2qcqmsw4v390z6L1cyAABAEAwyAABAEAwyAABAEKzJSEPDhg1Vjs+tH3XUUaru4IMPVnnZsmXhGoacq1evnsonn3yyynYuNs7OU3700Ucq23l65uVL2/HHH6/yoYceGpU3bNig6mxfyIZ9P9q+fbvK7MERXqtWrVQeNmxYlZ+7cuVKlWfOnBmkTftj36/se1Amqvt+xZUMAAAQRMpBhnOuo3PuRefcAufcPOfc1YmPt3DOTXXOLUr82zx8cwEAQKlIZ7pkt4iM8t7Pcs41EZG3nXNTReRCEZnmvR/rnBstIqNF5PpwTS0ce/RufArE3sZmt5N9++23wzUMOdeoUSOVTzjhhLS/1l6m/tvf/qbyxo0bq9+wMtakSRMZMGBAlF944YUCtiZ9TZs2VTl+afr5559XdfY2+Gzs2LFDZaZHwrPTDq+++qrKdpo1/noPHjxY1WX7emVyK2k20yO5kvJKhve+wns/K1H+XEQWiEh7ERkmIhMTnzZRRE4L1UgAAFB6Mlr46ZzrIiJHisjrItLae18hsncg4pxrVcXXjBCREfurQ81CX0CleF+oX79+gVuDQuJ9obylvfDTOddYRCaLyEjv/WepPr+S9368976f975fdRqI8kFfQKV4X6hTp06hm4MC4n2hvKV1JcM5V0f2DjAmee+fTnx4tXOubeIqRlsRWROqkYVm573s/FtcMcyBIbn4lr92ftTeHtikSROV7RqcuF27dql89913q0zf2L/PP/+8JNZh2Nf+8MMPr/Jzn376aZVzebtyLtd3ID3f/OY3VW7Xrp3Ktm988MEHUXnx4sU5bUup3fqezt0lTkQeEJEF3vu7YlVTROSCRPkCEXk2980DAAClKp0rGV8XkR+JyBzn3OzEx24QkbEi8oRz7hIRWSYi3w/TRAAAUIpSDjK89zNEpKprxCfmtjkAAKBcsK14Gux8W0VFRVS282P//ve/s3quZOsFMvXxxx+r3KVLl6wer1wkm9Ps06ePysm2EbfWrNHLktauXZv286L42btgLr30UpXjr+/s2bMll4488siofOqpp6q6X/7ylxk9lu2HydYZ1VT2qPabbrpJZfu+YNfJnHHGGVG5mNdi7dy5U+W6devm/DnYVhwAAATBIAMAAATBIAMAAATBmow02DnM888/Pyrbubts5zdzeQ4BazD2L/562rlVe3x3rVq1qvxaEf163XbbbVXWofTY3217vHebNm1Uju+Tsnnz5py25Z133onK2a73YA3G/sVf74EDB6q6zp07J/1ae5z7hx9+GJWLeS1WiDUYFlcyAABAEAwyAABAEAwyAABAEKzJSIOdU5s8eXJUPvvss1XdMccco/LSpUuTPradHy3m+btyZO9hf/zxx1W+7LLLVLbnk1x//fVRecKECTluHQqpQYMGKg8aNEhl+7s6b968qLxt27Zg7eI9Ioz4z3XRokWqbvXq1SovW7ZM5Z/85CcqF/PeGPnGlQwAABAEgwwAABAEgwwAABAEazKqYfr06VF51apVqs7O5aVi51fr1KkTle38P8J74403VG7cuHGBWlJz2Xv37fkK+WLXS7Vu3Tpp/fLly6Nyrn934z+TQv08yl38vdjuezFgwIB8N6dscCUDAAAEwSADAAAE4fJ5O5RzjnuvSoT3Pujew/SF0pHvvmCPLr/55ptDPj0ywPsCKqXbF7iSAQAAgmCQAQAAgmCQAQAAgmBNBvYr33Ovbdu2VfUVFRUhn77sNWzYUOWtW7dW+7Hy3Rdq1aql6vfs2RPy6astk3Y2b95c5Y0bN6p86aWXqnzfffdl2bowWJNR2mrX1rtWZLP9OWsyAABAQTHIAAAAQTDIAAAAQeR7TcZaEVkqIi1FZF3enjh9tGuvzt77g0M+AX2h2ugL+Ue79qIv0K5KafeFvA4yoid17i3vfb+8P3EKtCv/ivV7o135V6zfG+3Kv2L93mhX5pguAQAAQTDIAAAAQRRqkDG+QM+bCu3Kv2L93mhX/hXr90a78q9YvzfalaGCrMkAAADlj+kSAAAQBIMMAAAQBIMMAAAQBIMMAAAQBIMMAAAQBIMMAAAQBIMMAAAQBIMMAAAQBIMMAAAQBIMMAAAQBIMMAAAQBIMMAAAQBIMMAAAQRFaDDOfcEOfc+865xc650blqFAAAKH3VPurdOVdLRD4QkcEiskJE3hSRc7z383PXPAAAUKpqZ/G1/UVksff+IxER59xjIjJMRKocZDjnqjeiQd55713Ix6cvlA76AirRF1Ap3b6QzXRJexFZHssrEh8DAMQ459R/QE2RzZWM/f2m7DMKdc6NEJERWTwPygR9AZXoC6hEXyhv2azJOEZEbvHen5TIY0REvPe3JfkaLoWVCC6LohJ9IXv26kV133cLjb6ASvmYLnlTRLo557o65+qKyA9EZEoWjwcAZcl7r/4DaopqT5d473c7564UkedFpJaITPDez8tZywAAQEmr9nRJtZ6MS2Elg8uiqERfQCX6AirlY7oEAACgSgwyAABAEAwyAABAEAwyAABAEAwyAABAEAwyAABAEAwyAABAEAwyAABAENkckAYRqVu3rsp9+vRRedWqVSovX75cZbYYBgCUK65kAACAIBhkAACAIBhkAACAIDggLUvt2rVT+R//+IfKGzduVPnEE09Uec+ePWEalqWaehCSc/rbtr8ftn7r1q1ReefOnarunXfeUXngwIFJH2vXrl0q33bbbVH5/fffV3V/+ctf9ml7KDW1L4RUq1YtlQ84QP//nu0LxYK+gEockAYAAAqKQQYAAAiCQQYAAAiCfTKy9LWvfU3lHj16qLx69WqV69Spo3KxrskoZ02bNo3KmzZtUnUNGzZU2c6N7969W+XevXtH5YcffljVHX/88Spv27ZN5QEDBqhs113YNR4oLnZNTZs2baJy8+bNVd11112n8llnnZX0sYYPH65yPtfgIDX7Pl6sa2iKAVcyAABAEAwyAABAEAwyAABAEKzJyNJVV12lsp2rs5hnLzy7DiOuXr16Kjdq1CjpY918881RuX///kk/1867P/HEEyrff//9Kq9cuTIqP/bYY0kfG+HZ169x48Yqx1+jrl27Jv1ae+bRF198ofJRRx2lMmsyCqtnz54qT5o0SeXf/OY3Kk+fPj0q2/OrMhVfQyai916y/eqYY45ReebMmVk9dy5wJQMAAATBIAMAAATBIAMAAATBmoxqiJ870LFjR1Vnz7rYvn17XtqEL02cOFHlCy+8UOX4a9S6dWtV95WvfEXlG264QeW+ffuqHN8Pwc6PWq+99prKv//971W286cbNmyIyrVr619VO4dvM7JnX89jjz1W5QkTJqgc3ycjvp5GROSmm25S2fYru7/Oq6++mlljkbFk5xTZtVjf/e53Vbavl10zM2rUqKg8btw4VWdf+9GjR6tsf9ftXkrJ3meSrTcrFK5kAACAIBhkAACAIDjqvRril7Ps9sAPPfSQyna6pEWLFioX6y2tpXyk8ymnnKLy3/72N5XjW4fXr19f1dnL1Hb6JNnvi72MaS9znnfeeUnbZbcdT/d5QwvdF/r16+dff/31KNvLxZmwl7ErKipUtpeT46+Z/Rnb20zfffddlTt16qRy/JL5mDFjVJ197Oeff15l28/slvMLFiyQYlDK7wtpPHdUtscLzJ8/X+UDDzxQZXvr+4oVK6LyIYccouri0+3VEe9L9pgDe7trsveUbHHUOwAAKKiUgwzn3ATn3Brn3NzYx1o456Y65xYl/m2e7DEAAEDNk86VjAdFZIj52GgRmea97yYi0xIZAAAgknLy03v/snOui/nwMBEZlChPFJHpInJ9DttV1OJzYqmObLbz8hztnnsHHKDHyn//+9+Tfv7WrVujsl0TY+fZU71+n3zySVRu27atqrPHP7dr167KdtRkb7/9dlbrMOIGDhyo8pQpU1S2zxO/Tdj+7v7gBz9Q2d7uHH/tRUQuu+yyqGxvKbZrLA4//HCV7dqtTz/9VBCWfb3j7yN223D7u5vqsQ477LAq6zKVbD3Wm2++qXLINRjVVd01Ga299xUiIol/W+WuSQAAoBwE34zLOTdCREaEfh4UP/oCKtEXUIm+UN6qeyVjtXOurYhI4t81VX2i9368976f975fNZ8LZYK+gEr0BVSiL5S36l7JmCIiF4jI2MS/z+asRSXgoIMOisrf+ta3VJ1dH2Dn5VmTkXvZbKmd6gjuVNvEP/XUU1HZzrO//PLLKv/zn/+sdjuxf3Y/g/Hjx6tcp04dleNbf4voY7Ptmotvf/vbKq9du1bl888/X+V4P7RrP2bMmKGy3SvB9sMmTZqobPf7QPbse3WrVl/O+p966qmqLtkW5PvL8f0rUm0Lbvfmsce1J3uPsv3K9uHVq1dLoaVzC+ujIvKaiHR3zq1wzl0iewcXg51zi0RkcCIDAABE0rm75Jwqqk7McVsAAEAZYcdPAAAQRI056j3ZGQWZatasWVS2c/jW0qVLs3ouhJVqbtyuqbFHPsePb7fz8HbfjFztBYEvpdprxL5+y5cvVzk+L3/vvfequvgcvYjIrbfeqrI9z6Jly5ZReebMmaou1Wtv1wf06dNH5UWLFkXlQp5jU07szzG+NiLV3hZ2HZhdC7F+/fq022HXDfXv31/lV155ReV42xYuXKjq1qyp8h6MguFKBgAACIJBBgAACIJBBgAACKLGTBLH955fuXJlVo8Vn+dNdf/0k08+mdVzIayjjz5aZTvX+uGHH6psz7P42te+FpV/9rOfqTq7JsOu/xg6dKjKCxYsUDm+nqdBgwaqrhjPKChFLVq0iMpHHXWUqmveXB8ufdVVV6n8X//1XyrH9+BItd+KZfdSsGu5WIeRe6eddprKXbp0Sftr7R44mazBsOxeL3fccYfK9rWPv0fZNUbF2E+4kgEAAIJgkAEAAIKoMdMl2U6RxHXo0CEqp7rVadWqVTl7XuSevXXQ3hLZvXt3lQ899FCV45cu7ZRGqr7x3HPPqXzyyServGzZsirbMXv27KSPXVPEt/gXyfyydfzy8uTJk1Xd8OHDVe7du7fK9vWNH/3+0EMPqbpTTjkl6WNZxbAddLn70Y9+lPbn2uksu+V8NuzUZybvI2PH6s22+/UrvuNfuJIBAACCYJABAACCYJABAACCqDFrMrJh58ROP/30qGzn9K3PP/88SJuQG9OnT1d56tSpKtttxO02vvHbGH/xi1+ounXr1ql8/PHHq2z7zr/+9S+V4+sFWIOxf9ncOmi//rrrrlN1//d//6fyd77zHZVffPFFlf/6179GZXsr9LBhw1S27ylz585VOZdryLCX/ZnHb19Oxf4ux49yz7Yd8WMqREQ2bdqU9PPj2d52bd9TbM6m3dXFlQwAABAEgwwAABAEgwwAABAEazLSYOfE4ve42zp7P7Wd80dxsXPn3/ve91ROdUR3/PV+6qmnVJ2dD92yZUtGbUF+7dy5U2W7JsNm+7seX0PTs2dPVdejRw+V7dy4PRq+EHPn5cZuGx4/yl1EHw8hoo8Q6Ny5s6qze6hkwr4PHHjggSoPGjRIZbudvX1fiD+e3WPDfm4xvKdwJQMAAATBIAMAAATBIAMAAATBmow0tGzZUuVvfOMbVX7unDlzVN64cWOQNiEMu8amUaNGKtt1FcmOVrbzofXq1VN5+/bt1W6XzcUw91pu7Jy9lew1qVOnTtLPtezR7sjeNddco/KIESNUPvbYY1WO700S3/9GZN/j1zNhf+/t0e7278sRRxyhsu078fcc+7XFiCsZAAAgCAYZAAAgCAYZAAAgCNZkpOGEE05QOdneCbNmzVKZufLS0qpVK5V37NihcuvWrVVOdsaEvT/e7sNg622/SrZXAv2q8JKtx7HrturWrauyPdNo2bJlaT820jNw4ECVTznlFJXPPPNMlZs2bRqV16xZk7N22N9ru87rjDPOUDnVeVjxdX5bt27NsnXhcSUDAAAEwSADAAAEwSADAAAEwZqMNJx88slV1tm50+uvvz50c5BDdv7TrslYvXp10s9PJtXeFvaskz59+qj81ltvRWU7r2vPzWCNRuHVr18/Kl9xxRVJP9eut3nppZeCtAlf+tvf/pa03p4Dkiv2HJuRI0eqbM9JsX3DtqtFixY5bF14Kd8xnXMdnXMvOucWOOfmOeeuTny8hXNuqnNuUeLf5qkeCwAA1Bzp/G/ZbhEZ5b3vKSJHi8gVzrleIjJaRKZ577uJyLREBgAAEJE0pku89xUiUpEof+6cWyAi7UVkmIgMSnzaRBGZLiJlMVdgL2vPmDFD5R/+8IdR2V6m3rBhQ7iGIbghQ4aofO+996qcya1thx56qMqpthGPHzVt2Uuo3OJYfOLbRdtL4Pb1sv1o/fr14RqGvIv/DZkyZYqqs1vOV1RUqPzZZ5+pfP/99+e4dfmV0cJP51wXETlSRF4XkdaJAUjlQKRV1V8JAABqmrQXfjrnGovIZBEZ6b3/LNWBP7GvGyEiI1J+IsoefQGV6AuoRF8ob2ldyXDO1ZG9A4xJ3vunEx9e7Zxrm6hvKyL7vY7svR/vve/nve+XiwajdNEXUIm+gEr0hfKW8kqG23vJ4gERWeC9vytWNUVELhCRsYl/nw3SwiKwcOFCleO3Mdptp7mVsLT06NFD5auuukrle+65p9qP3a1bN5Xt7bDXXnutyps2barysViDUXzs7cwnnnhiVLbbiNtbju+66y6Vk20hj+Jnr+zHb2E++OCDVZ39G/Hiiy+qbI+Gv+GGG3LRxIJJZ7rk6yLyIxGZ45ybnfjYDbJ3cPGEc+4SEVkmIt8P00QAAFCK0rm7ZIaIVLUA48QqPg4AAGo4thUHAABBsK14GuwRwfH5cbv3gZ2bYy69+MTn0ufPn6/q2rVrp/KWLVtU/uijj1SOz7136NBB1dn1OnfeeafKdq8E1vMUN/u7Hd9GXETk4osvjsp2vYbd+2DSpEk5bh0KKb5HiojI3Xe+cL38AAAgAElEQVTfHZVtX7DHs48ZM0bliy66SGW7nqfUcCUDAAAEwSADAAAEwSADAAAEwZqM/bDrKOze8z/5yU+i8iOPPJL0a1F8Mln7YOfh7Xkkydg5+2ef1VvJlPpca01j+8JBBx2kcrxv2NfW7rVj1+ugtDRvrg8d79Onj8q1a3/5p9X+TahVq5bKH3/8scq33nprDlpYPLiSAQAAgmCQAQAAgmCQAQAAgmBNxn7YudclS5ao/M9//jMqP/DAAzl9LtZ0FNbIkSNVtntb2HMF4nPvdq51165dKs+aNSsXTUSB2LU8ds3N3Llzo3Ljxo1V3XXXXZf0sVBatm3bpnKnTp1Ujr8vbN68WdUtX75c5XJ/z+dKBgAACIJBBgAACIJBBgAACMLlcz7IOVfek09lxHtf1cm7OVGOfSF+jomIyM6dOwvUktyiL+yffb07d+4clXv37q3q7F47dr2OZdd72DOSCoW+sJd9fRYvXqxykyZNovKgQYNU3apVq5LmUlmjkW5f4EoGAAAIgkEGAAAIgukS7BeXRVGJvoBK9IW92rdvr/K8efOqzMcdd5yqs0e/16lTR+VimRpLhekSAABQUAwyAABAEAwyAABAEKzJwH4x94pK9IXwSuV4AfoCKrEmAwAAFBSDDAAAEASDDAAAEES+j3pfJyJLRaRlolxsaNdenVN/StboC9VDX8i/4O2q5hoM+kL+0a690u4LeV34GT2pc2957/vl/YlToF35V6zfG+3Kv2L93mhX/hXr90a7Msd0CQAACIJBBgAACKJQg4zxBXreVGhX/hXr90a78q9YvzfalX/F+r3RrgwVZE0GAAAof0yXAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAILIaZDjnhjjn3nfOLXbOjc5VowAAQOmr9lHvzrlaIvKBiAwWkRUi8qaInOO9n5+75gEAgFJVO4uv7S8ii733H4mIOOceE5FhIlLlIMM5V70RDfLOe+9CPj59oXTQF1CJvoBK6faFbKZL2ovI8lhekfgYAABAVlcy9jeK2WcU6pwbISIjsngelAn6AirRF1CJvlDeslmTcYyI3OK9PymRx4iIeO9vS/I1XAorEVwWRSX6AirRF1ApH9Mlb4pIN+dcV+dcXRH5gYhMyeLxAABAGan2dIn3frdz7koReV5EaonIBO/9vJy1DAAAlLRqT5dU68m4FFYyuCyKSvQFVKIvoFK6fSGbhZ8AUFIOOEDPEH/xxRcFaklxatCggcrbtm0rUEtQLthWHAAABMEgAwAABMF0SZGpVatWVN6zZ08BWwKUH6ZHkmN6BLnGlQwAABAEgwwAABAEgwwAABAEazIKrGXLliqvXr06Ku/atUvV/fjHP1b5wQcfDNYuAED+devWTeVZs2apXLv2l3+27d+ESZMmqbx79+4cty5zXMkAAABBMMgAAABBMMgAAABBsCajwC688EKV49se2y2Q165dm48mAQByxDl9xIc9Lyy+xkJE5MUXX1S5YcOGVT7eJZdcouomT56s8ubNmzNrbABcyQAAAEEwyAAAAEEwyAAAAEGwJiPPmjVrpvKoUaNUjs/Xbdy4UdXNnDlTZY6tBsKxc+n2961Dhw4qn3766VH5u9/9rqqLn0kkItK3b1+V69Wrp7Ld32DcuHFR+fbbb1d1GzZsUNnO+aOw7Oth+8Lw4cNVbteuXdLH27lzZ1T+4x//qOqK8W8AVzIAAEAQDDIAAEAQDDIAAEAQLp/zd865gk0Wtm3bNipXVFTk7XntPG583lZE5LHHHlM5Pg88depUVWfneUPuS++9d6k/q/py2Rfsfeb2Z/yzn/1M5TvvvDMq2/ns5cuXq5yqr/z0pz+NykOGDFF1hxxyiMp2Ltbe/16nTh2V43Ov3/nOd1Td9OnTVQ75e1xKfSEb9ne1c+fOKj/++OMq9+rVS+UGDRpEZbuew7KvV6rPj1u1apXKRx55pMp2LVe8H2WrpvSFkM4991yVJ0yYoHLdunVV3rNnj8pbt26Nyu3bt1d1W7ZsUbkY3he4kgEAAIJgkAEAAIJgkAEAAIKoMftkrF+/viDP27x5c5VvuOEGle2c2ZIlS6LyD3/4Q1UXcg1GKbP3hl966aUqf/WrX1V50qRJUdn+/O1e/3Z+ND7vLpLZXHqm4nsnnHzyyaru448/VtmuD5gxY4bKmzZtym3jykT89Rs4cKCqe+6551Ru1KhRlV8rknz+266LsHnbtm0q2/eN+Lqjli1bqrof//jHKtu9E9asWVNluxCeXXt1xRVXqGzXlNn3M9tXbr755qhcDGeTpMKVDAAAEASDDAAAEESNmS7ZtWtXXp7H3gb3xhtvqBy/lVZk31uOnnrqqaicaoonk8u15cR+3/Yytp3SsLeO2hxnt30vpPj3eeWVV6q6xo0bq2ynR/LV30uN7TsHH3xwVL777rtVXaqpMXtZe9myZVE5vg24iMjTTz+tsr112t6m+Otf/1rl+CV223/PO+88le+66y5B8bDv+f/xH/+hsn09bb+y/e7NN9/MYevC40oGAAAIgkEGAAAIIuUgwzk3wTm3xjk3N/axFs65qc65RYl/myd7DAAAUPOksybjQRG5R0Qein1stIhM896Pdc6NTuTrc9+83InPa4Vcu9CjRw+V7dy5veXolVdeUfk///M/036umrIGw7JzlB07dlTZbgcd8jbTODuXal8fm+2ta7Y+2bqKM844Q+V77rlH5fjWw/hSq1atVH7iiSei8uGHH67q7Poqewv5woULVe7fv39U3r59u6pLtZ7Dbin/ve99r8qvt+s3bLbrvJB/8dfzF7/4haqzv/eWfR+wt5/Pnj07y9blV8orGd77l0Vkg/nwMBGZmChPFJHTctwuAABQ4qq7JqO1975CRCTxb6sUnw8AAGqY4LewOudGiMiI0M+D4kdfQCX6AirRF8pbdQcZq51zbb33Fc65tiJS5b613vvxIjJepLDH+No50Fyx82tvv/120s//y1/+ovJ///d/q2zncstJrvpCfO5bZN+9SOx8dnzvERG9LXP9+vVV3Weffabyjh07VH7vvfdUvuaaa6Jyhw4dVN0xxxyjsj36/Vvf+pbKTZs2VdnO08fZtT72yOf58+dX+bXFoFDvC/fdd5/Kxx57bFS2azDsWoeHHnpI5csuu0zlZNv+2zUZ9rW1W4PH9+8Q0fP0ds5++vTpKtut8Iv9PaVY/kbk0jnnnBOVzzrrLFVn+4LtZxUVFSrH32NESm/NTXWnS6aIyAWJ8gUi8mxumgMAAMpFOrewPioir4lId+fcCufcJSIyVkQGO+cWicjgRAYAAIiknC7x3p9TRdWJOW4LAAAoI2V7domdX83lmoz4nJq9t97Otdr5N3tE9+LFi1WuqXtfZMKuwbBz0HZdjH2N4p/fqVMnVTd37lyV7Tx7sj037NfOmjVL5eHDh6ts9/c4+uijVY73YTuvfscdd6g8derUKtuFL9m+kGz/nPHjx6t87bXXqpxsDYZ14IEHqvyrX/1KZds37HkW8bbZOXnbLs6tyT/7HjR69OioXK9evaRfa99T7r33XpUnT56cZesKi23FAQBAEAwyAABAEAwyAABAEC6fawDK5R7o+PkkL7/8sqqL78Egsu/8qZ2H//TTT3Pcutzw3gc98KNc+kKcnVu18/B2X4xx48apbPdGiD/eJ598our69eun8qpVqzJrbAZKuS/YtVkvvviiyt/4xjeist0TpWfPniqvWLFCZfveGX+uLl26qLrHHntMZbs2JNW8fXydRXxvD5F91yDl8j09vg/Q7t27S7ovhNSuXTuV4/vU2P1vrPXr16ts99sp1n1O0u0LXMkAAABBMMgAAABBlO0trLnUoEEDlV944YWobKdH7K2yf/jDH1S221ajfNjL1Js3b1bZbh1tjx230y3xy/fr1q1TdWvXrq12O2sS+/uY7BZk+7l2uqR3794q2/eFAQMGROUrrrhC1dlbHFOxbZk2bVpUDjk9YmVym25NYqfhzjzzTJXj2/7b18fmCRMmqLxz585cNLFocCUDAAAEwSADAAAEwSADAAAEwS2sabC3jMVvg0t1rHL8dlcRkaVLl+a4dWFwq1r2zj//fJX//Oc/q2zXB9gcvz3a3gL5xz/+MRdNTEs59YX27durvGTJkqhst/LeunWryvbIgPjtnSJ6nj7Z2o90bNu2TeX49vd2fU4+lVNfyMZBBx2k8oIFC6qst+s37DqXvn37qjxnzpxcNDE4bmEFAAAFxSADAAAEwSADAAAEwT4Z+2Hn0K655hqV43O3dk3Lddddp/Ly5ctz3DoUq6985Ssq2/vfbb+y7Hqe+FHx999/f5atg4jIypUrVf79738flS+//HJV16hRo2o/j31fSLVGw+6L8c4776jM/jqFZX93TznlFJVbtGihcvz1tn0hvs+SiMjixYtz0cSixZUMAAAQBIMMAAAQBIMMAAAQBPtk7EfXrl1Vjh/bKyJSv379qGzvpbdHuW/YsCHHrcsP7odPT/yMgnnz5qm6+N4G+2N/9xYuXKjyMcccE5U3bdpU3SZmrZz7QuvWraOyPVvmoosuUtnuk7FmzRqV42s4mjVrpursGUeW3T+nX79+KtvjwAulnPtCMk2aNFF56tSpKvfv31/l+JoMexZJr169VLavfamcF8M+GQAAoKAYZAAAgCAYZAAAgCDYJ0P2vR9+xowZKsfXYIjoufQHHnhA1RVy7hzhNWjQQOVnnnkmKttzMVKxc6/nnXeeyvSl8OLrKu644w5V9/DDD6ts96rYsWOHyt/5znei8sSJE5M+r33tb7rpJpU//fTTpF+PsOy+JkceeaTKRxxxRNLPj/+N+PDDD1Wd3Q+nVNZgVBdXMgAAQBAMMgAAQBAMMgAAQBA1ck1G/OwREZFrr71W5YMOOijp18fnYn/xi1+ouj179mTZOhQTO9d62GGHqTxo0KCobPuVZc+nmDx5ssr2vAqEF587t3PlS5YsqfJzRfZ9vXv27BmV7Z4ath/Z5/r73/+uMu8jhWX3O7r99ttVrl07+Z/O+N+I4cOHq7pVq1Zl2brSwpUMAAAQRMpBhnOuo3PuRefcAufcPOfc1YmPt3DOTXXOLUr82zx8cwEAQKlIZ7pkt4iM8t7Pcs41EZG3nXNTReRCEZnmvR/rnBstIqNF5PpwTc2dVq1aqTxmzBiV69atq7K9dDlu3LioXMhbzZLdNoXcsFuD276SbIok1bbh5557bpatQy7Z6axU7PHfP/3pT6Oy/d207yGPPfaYyhs3bszouZF78dcsvqW/iMiAAQOq/Nz9ib+eW7ZsUXU17X065ZUM732F935Wovy5iCwQkfYiMkxEKm8Gnygip4VqJAAAKD0ZrclwznURkSNF5HURae29rxDZOxARkVZVfyUAAKhp0r67xDnXWEQmi8hI7/1nqS4Xxb5uhIiMqF7zUE7oC6hEX0Al+kJ5S2uQ4ZyrI3sHGJO8908nPrzaOdfWe1/hnGsrImv297Xe+/EiMj7xOMEmo1KtTzjhhBOi8hlnnKHq7BoMa86cOSr/7ne/q04Tc67U5vby1RdyqWvXriqffvrpKsf7nX097Dz7wIEDVS611y+XSrEv2DUYJ510ksqNGzeOyva1tcd933LLLbltXAkrlr4Q37og1S3IqcydOzcq29c+07U/pS6du0uciDwgIgu893fFqqaIyAWJ8gUi8mzumwcAAEpVOlcyvi4iPxKROc652YmP3SAiY0XkCefcJSKyTES+H6aJAACgFKUcZHjvZ4hIVdeKTsxtcwAAQLkom23F7ZyZ3b9gw4YNUfnkk09O+rX26N3jjjtO5a1bt1a7nShuTZs2Vfkf//iHyvXq1VM5Pvdu90zp27evyuyFUHiZ7C1j12DYrab/9Kc/VfnY9nHfe+89lTdt2pT0uULO29u2ZbreoFSl2vY//vsbPy5AZN99TlI91jPPPBOVV69enWYLyxPbigMAgCAYZAAAgCAYZAAAgCDKZk2GncNMtkZj165dqs6uwRg9erTKdu95lA/bTx544AGV69evn/Tr4+tzhg4dqupWrlypcqq58Jq8b0YoufwZN2vWTOXWrVtX+bnxo75FRK6++uqk9flck1FT1mBYdl1FMnfeeafKdh1fmzZtVF6yZInKf/3rX6NyIc+3KgZcyQAAAEEwyAAAAEEwyAAAAEGUzZoMy86/vf3221G5R48e+W4OilS7du1UHjJkSEZfv2jRoqj81ltvqTq71gfVE1+vkOlahWzWYNg9UWzfsGsb4u857777rqqzOdW+Pvb7rGnnXRTawoULVW7fvn2BWlL6uJIBAACCYJABAACCYJABAACCKNs1GUA6TjxRn/GX6R4C8X0ymDcPo1h+rtu3b1d5586dKs+ZMycqjxw5Mulj2e/J7t1Tu7Z+ay6WnwGQKa5kAACAIBhkAACAIFw+tzJ2zrFvconw3gfdezhkX8hkK+lDDz1U5V/+8pcqn3vuuSpv3rxZ5QEDBkTlBQsWZNTOUpHvvsB268WrlN8XkFvp9gWuZAAAgCAYZAAAgCAYZAAAgCBYk4H9Yu4VlUqpL7CeI6xS6gsIizUZAACgoBhkAACAIBhkAACAIPK9rfg6EVkqIi0T5WJDu/bqnIfnoC9UD30hiUBrMOgLe5VUXwiEdu2Vdl/I68LP6Emde8t73y/vT5wC7cq/Yv3eaFf+Fev3Rrvyr1i/N9qVOaZLAABAEAwyAABAEIUaZIwv0POmQrvyr1i/N9qVf8X6vdGu/CvW7412ZaggazIAAED5Y7oEAAAEwSADAAAEwSADAAAEwSADAAAEwSADAAAEwSADAAAEwSADAAAEwSADAAAEwSADAAAEwSADAAAEwSADAAAEwSADAAAEwSADAAAEkdUgwzk3xDn3vnNusXNudK4aBQAASl+1j3p3ztUSkQ9EZLCIrBCRN0XkHO/9/Nw1DwAAlKraWXxtfxFZ7L3/SETEOfeYiAwTkSoHGc656o1oqsE5p3J1B1M1lffepf6s6stnX0B26AuoRF9ApXT7QjbTJe1FZHksr0h8rCjUqVNH/QcAAPIrmysZ+xvF7DMKdc6NEJERWTwPygR9AZXoC6hEXyhv2azJOEZEbvHen5TIY0REvPe3JfmavF0Kq1u3rso7d+7M11OXBS6LohJ9AZXoC6iUbl/I5krGmyLSzTnXVURWisgPROTcLB4vpxhUAABQWNUeZHjvdzvnrhSR50WklohM8N7Py1nLAABASav2dEm1noxLYSWDy6KoRF9AJfoCKuXj7hIAAIAqZbMmA6jxDjjgy3H6F198UcCWAEDx4UoGAAAIgkEGAAAIgukSIAtMkSAXatWqpfKePXsK1BIgt7iSAQAAgmCQAQAAgmCQAQAAgijomozatfXT7969u0AtAfbq1auXyvPnzy9QS1CTnHHGGSo/+uijKh9xxBFReeHChXlpE5ALXMkAAABBMMgAAABBMMgAAABB1MgD0ho3bqzy5s2bC9QSEefSP2+oQYMGKm/fvl3lXO7ZwEFIqERfCG/lypUqt23bVuVPPvkkKnfo0CEvbdof+kJxa9mypcrr1q0L9lwckAYAAAqKQQYAAAiCQQYAAAiixqzJiK99sN+z3a/Drm2wnx/P9syB1q1bqzxw4ECVx40bp3L9+vVVjh8dfuONN6q63/3udyqHPN+Audf9s+t5OnXqFJV79+6t6h555BGV46+tyL797N1331X55ptvjsrTp09XdVu3bk36WLlEX8g92xd27typsl2r1b9//6j89ttvh2tYCvQFVGJNBgAAKCgGGQAAIAgGGQAAIIgasyYjzs53NmvWTGV7r/HatWtV/u53vxuVzzrrLFU3aNCgpM9dp04dlevWrVtl2+w8e/z8ApF9zzDI5WvJ3Ote3bp1U/mVV15RuVWrVlE5kz1P9se+ftu2bYvK559/vqp75plnkn4tfaG4XX311Sr/9re/Vdnu3RN/jwq5FisV+kJ64vuc/OUvf1F1qf5GrF+/XuXZs2erPHLkyKj80Ucfqbr4e4bIvu9JhdhLiSsZAAAgCAYZAAAgCAYZAAAgiNqpP6U02LUN3bt3V/nTTz+Nyscff7yq++Mf/6iyPSPEzm/H57mWLVum6hYvXqzyG2+8ofKpp56qst1XIy7V/Fk+19MUk48//ljlLl26BHuu4447TuUDDzxQ5WTrMOzc+e7du1W2+7PYvRPq1asXle2eG3a/jpD7ZCD3brvttqT19n2jkOswylWytXmbNm1Sdfb3y37tYYcdpvLcuXOjsv09t6+lfez3339f5YYNG6p83XXXReWf//znqm7FihVJH7sQuJIBAACCYJABAACCKNnpkn79+qn84IMPqhzf7llE3zqa7LZRkX2nIXbt2qVy/FLmqFGjVF1FRYXKI0aMUPnggw9O+tzxy1vxS24iIkuWLBGEnR6xzj77bJXtpc7JkydH5ZNPPlnVrV69WuXLL79c5SuvvFLloUOHqhzfst5OpTRp0kTl+HTg/tjt77n8nl92estOyVq//OUvQzYHItKiRQuVb7rppqhsj3Cwv8vxKQsRfQSASPJjLOzvst0i4atf/arKtu/E//bNnDlT1d13330qM10CAADKVspBhnNugnNujXNubuxjLZxzU51zixL/Ng/bTAAAUGrSuZLxoIgMMR8bLSLTvPfdRGRaIgMAAERSrsnw3r/snOtiPjxMRAYlyhNFZLqIXJ/DdqVkj7pu3769ynatQ3xOetWqVarO3qaYah4rfpuQnW9r2rSpyhdffHGV7djf12/YsCEqn3766apu+/btSduF7Nl+c95556ls+138NbFzvPZ25XfeeUflLVu2qJzsluQ//OEPKqdag2GxBiO/7Lz7448/rrJ9rW2/6ty5c5iGIWJvOx08eHBUPuGEE1Sd/f3p06ePysluZU913IC9LT5+6/r+vj7et+w24sX4e17dNRmtvfcVIiKJf1ul+HwAAFDDBL+7xDk3QkRGpPxElD36AirRF1CJvlDeqnslY7Vzrq2ISOLfNVV9ovd+vPe+n/e+X1Wfg5qBvoBK9AVUoi+Ut+peyZgiIheIyNjEv8/mrEVpssex2/uD7T4C8aOVd+7cmdVzx+fImjfXN9bMmDFD5Xbt2iV9LLvOIn6cu703G+HZuXJ77HIydp1EfJtiEZGuXbuqbI9w7tmzp8rxrfEffvjhtNuBwoi/L9g1YnYPlOXLl6v8ta99TWW7Xge516tXL5Xj23e3adNG1aXa1yQbds1FqjUc8TWDdv1gMR41kc4trI+KyGsi0t05t8I5d4nsHVwMds4tEpHBiQwAABBJ5+6Sc6qoOjHHbQEAAGWEHT8BAEAQJXt2yWuvvaayPRo55J4S8fm5YcOGqTo7727vl7dzZnYP/DVrqlxDiyIXX0Mhou+7F9n37JKPPvpI5eeee07l+Fk1s2bNyqgtrVrpu8rpV7ln587PPPPMqHz77bcn/dqXX35Z5c8++0zlYtzvoNTY18ceuX7hhReq3Lp166hcv359VWfft+1aCJvjZ2XZOrsm8PXXX1f561//usr2b0h8L6V58+ZJseNKBgAACIJBBgAACIJBBgAACKJk12Ts2rUraQ4pvt6jcePGqs7On1k7duxQ+d///rfK8XnEYrznuaazr+8jjzwSlTt16qTq7F4ta9euVfnzzz9X2a7J+PWvfx2VU52nY7EGI7wzzjhD5R/+8IdR2a4Js7/Lc+bMUZk1GLlnf+Z2TUbdunVVjq+j2LRpk6qze9jE10WIiBx55JEqx3/X7X5H8bUfIiLjxo1L2k67hiO+ZiO+bktk3/enTN83QuBKBgAACIJBBgAACKJkp0sKKX5J6itf+Yqqs5e6kn2tiMjo0aNVPvfcc7NsHSz7M48frWx//itXrlT5t7/9rcr2trj4NN2KFStU3ZNPPqnyZZddpnL//v1V7tu3r8qnnXZaVLaX11F49nj2+Lby9hhxe8mcbeLzzx6LfuONN6ocn560t5Gmms6yt6Fmwt7qbqc44u8DIvrW91KYUudKBgAACIJBBgAACIJBBgAACII1GdUQvzXRzqfZ+f/du3er/N5776l8xx13qFwMtxyVm/POO0/l+JbPbdu2zeix7OsT3xZ+4sSJqu6+++5T2d7ubG+7Puuss1SeO3duRm1DWHa9lb2FNb6t+Lp161TdM888o7Jdz4H8+9e//qXy0UcfHeR57K2y9957r8r2b4bdKnzq1KkqZ7IOw64h69y5s8off/xx2o9VXVzJAAAAQTDIAAAAQTDIAAAAQbAmIw12zuyII46IyvZ+eMvOu1900UUqL1y4MMvWwYpvDyyy7xyorY+z852vvPKKyqeeeqrK8a3B4/fZi4icfvrpKtv50RdeeEHld999N2lbUFh2zUyyPW2WLl2q8k033aSy3bYapc3+jWjQoEFUvuWWW1Tdt771LZXt73l8bY/Ivuv6MmEfOx9rMCyuZAAAgCAYZAAAgCAYZAAAgCBYk5EGO5d+//33R+VatWqpOrvHvT2m98MPP0z6+cg9uybj6quvjsr29fnHP/6hsj03wGrUqFFUvvzyy1Wd7RuLFy9W+cEHH1Q5m7lX5F58Xl1E5JBDDlG5fv36KsePd/+f//kfVRc/1wTlp2HDhirHz0Sy7wt2ncT48eNVXrRoUY5bV1hcyQAAAEEwyAAAAEEwyAAAAEGwJmM/7D3P7du3V7lLly5Vfm183wSRfe9LtvNxdr0HeyNk76qrrlLZnh3wzW9+Myq/+uqrqi7TNTLx+VN7Noll749ftmxZRs+F/Dr88MNV7tatm8rJzil69tlnwzUMRadXr14qX3nllVG5Xr16qm7Lli0qX3PNNSqX298ArmQAAIAgGGQAAIAgGGQAADzXMuAAAAf1SURBVIAgWJMh+86txvc+EBGZP3++yvE5fru3gT2LxGbWYIR31113qdyjRw+VszkvpnPnziq3bdu2ys+16zvyuQajefPmKm/cuDFvz10ufv7zn6vctGnTpJ8fP6vGrs1CebPn2hx44IFR2b4P3H777Spv27at2s9r/3Z98cUX1X6sUFJeyXDOdXTOveicW+Ccm+ecuzrx8RbOuanOuUWJf5uneiwAAFBzpDNdsltERnnve4rI0SJyhXOul4iMFpFp3vtuIjItkQEAAERExGV6ud4596yI3JP4b5D3vsI511ZEpnvvu6f42qKcG7DbBz/11FMqDxkyROX4lEdFRYWqmzJlispjxoxR2R7xXKzTJd57l/qzqq9Y+4JltwZfv369yvHLovYS+YABA1TOZpqmkGpqX7CXnu3U6AsvvKDy0KFDg7ep0GpqX7Dq1Kmj8nvvvady9+5f/incvHmzqmvTpo3KW7duzXHr8iPdvpDRwk/nXBcROVJEXheR1t77isSTVYhIq8yaCAAAylnaCz+dc41FZLKIjPTef2YXMCb5uhEiMqJ6zUM5oS+gEn0BlegL5S2tKxnOuTqyd4AxyXv/dOLDqxPTJJL4d83+vtZ7P95738973y8XDUbpoi+gEn0BlegL5S3llQy395LFAyKywHsfvzdwiohcICJjE/+W7D663/72t1UePHiwyvY2oR07dkTld999V9U9/fTTKtv5tmJdg1GTxNfg2NvLbrzxRpUvuOACle1c7MSJE6PyxRdfrOp4rYtf/PU86qijVF2qIwDs9vUoX6mu3G/fvl3l+PvKG2+8oepKdQ1GdaUzXfJ1EfmRiMxxzs1OfOwG2Tu4eMI5d4mILBOR74dpIgAAKEUpBxne+xkiUtUw7sTcNgcAAJQLthUHAABBlO224nZ/gzh79Pf48eNVtvPudm42fnz7n/70J1U3bdo0le299vncVrx2bf3y2vv8a6qdO3dG5TvvvFPVXX311Um/1q67ePjhh6NyMa/BSLW+oKZq2bJlVB47dqyqW7NGr2VfunSpyh999FG4hqGo2N+Xb3zjGyp369atys//6U9/Gq5hxrHHHqvyq6++mrfnrgpXMgAAQBAMMgAAQBAMMgAAQBAZn12S1ZMF3JferrOIz7vb+t/+9reqbvjw4SrbNRn2sU499dSo/NJLL6k6e7+0ZR97165dST+/UMr5jIKOHTtGZTuvbtexfPrppyq3aNFC5ZC/P/E+a/tgPpVzX+jRo0dUnjlzpqp75plnVB49Wp8BuXr16nANK1Ll3BeSGTVqlMr2nJrjjz9e5fj6t+bN9QHl2RztXkyCnF0CAACQLgYZAAAgCAYZAAAgiLLZJ8PuR2HXPtg1G3H2bBL7WO+8847KL7/8clROtQYjVTsRnt0z5bLLLovKdk2FnS/N5xoMq5DrMGqKhQsXRuVmzZoVsCUoJnZfjF/96lcqJ9uHSURk/vz5Ublc1mBUF1cyAABAEAwyAABAEAwyAABAEGWzJiPVuRzxObRbbrlF1fXu3TvpY5122mkqZzPHtmfPnmp/LdJz1llnqfzEE0+o/Pnnn0dlux7HzssX83kkAMKw++XYNX32fcO+Tzz11FNhGlaCuJIBAACCYJABAACCKJttxZFbNXX7YOyLvoBKNaUv2GnTDRs2qGxvcV23bp3K7du3j8rleis624oDAICCYpABAACCYJABAACCYE0G9qumzL0iNfoCKtXUvpDq6ImaiDUZAACgoBhkAACAIBhkAACAIPK9rfg6EVkqIi0T5WJDu/bqnIfnoC9UD30h/2jXXjW2L8TWYBRVu2KKti/kdeFn9KTOveW975f3J06BduVfsX5vtCv/ivV7o135V6zfG+3KHNMlAAAgCAYZAAAgiEINMsYX6HlToV35V6zfG+3Kv2L93mhX/hXr90a7MlSQNRkAAKD8MV0CAACCyOsgwzk3xDn3vnNusXNudD6fez9tmeCcW+Ocmxv7WAvn3FTn3KLEv83z3KaOzrkXnXMLnHPznHNXF0O7QqAvpGwTfaEwbaEvFBB9IWWbSq4v5G2Q4ZyrJSLjRORkEeklIuc453rl6/n340ERGWI+NlpEpnnvu4nItETOp90iMsp731NEjhaRKxI/o0K3K6foC2mhLxTGg0JfKAj6QlpKry947/Pyn4gcIyLPx/IYERmTr+evok1dRGRuLL8vIm0T5bYi8n6B2/esiAwutnbRF+gL9AX6An2h8D/zUugL+ZwuaS8iy2N5ReJjxaS1975CRCTxb6tCNcQ510VEjhSR14upXTlCX8gAfaHgiuZnTl8ouKL5mZdKX8jnIGN/x8Jya8t+OOcai8hkERnpvf+s0O0JgL6QJvoCKtEXUKmU+kI+BxkrRKRjLHcQkU/y+PzpWO2caysikvh3Tb4b4JyrI3s7zyTv/dPF0q4coy+kgb5QNAr+M6cvFI2C/8xLrS/kc5Dxpoh0c851dc7VFZEfiMiUPD5/OqaIyAWJ8gWyd74rb5xzTkQeEJEF3vu7iqVdAdAXUqAvFBX6Qn7QF1Ioyb6Q50UqQ0XkAxH5UERuLPCCmUdFpEJEdsneEfQlInKQ7F2Zuyjxb4s8t+k42Xt58D0RmZ34b2ih20VfoC/QF+gL9AX6QnX+Y8dPAAAQBDt+AgCAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIBhkAACAIP4f7hq2WdaXb6kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x648 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    savere = tf.train.Saver()\n",
    "with tf.Session(graph = graph) as sess:\n",
    "    checkpoint = './checkpoints/generatorg.ckpt'\n",
    "    savere.restore(sess, checkpoint)\n",
    "    sample_z = np.random.uniform(-1, 1, size=((16, 100)))\n",
    "    sample_z = tf.to_float(sample_z)\n",
    "    gen_samples = sess.run(\n",
    "                   generator_forward(sample_z, input_size, n_units=g_hidden_size, reuse=True, alpha=0.01))\n",
    "                   #feed_dict={gen: sample_z})\n",
    "view_samples(0, [gen_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
